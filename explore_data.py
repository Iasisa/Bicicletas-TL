#!/usr/bin/env python3
"""
Script para explorar los datos transformados del pipeline ETL
Ejecutar: python explore_data.py
"""

import pandas as pd
from pathlib import Path

# Configurar pandas para mostrar mÃ¡s informaciÃ³n
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
pd.set_option('display.max_colwidth', 50)

print("="*80)
print("EXPLORACIÃ“N DE DATOS - Pipeline ETL Bike Sharing")
print("="*80)

# ============================================================================
# 1. DATASET COMPLETO TRANSFORMADO
# ============================================================================

print("\n" + "="*80)
print("1. DATASET COMPLETO TRANSFORMADO")
print("="*80)

df_full = pd.read_parquet('data/processed/bike_sharing_full.parquet')

print(f"\nDimensiones: {df_full.shape[0]:,} registros Ã— {df_full.shape[1]} columnas")
print(f"\nRango de fechas: {df_full['dteday'].min().date()} a {df_full['dteday'].max().date()}")
print(f"Total de rentas: {df_full['cnt'].sum():,}")

print("\nğŸ“‹ Columnas disponibles:")
for i, col in enumerate(df_full.columns, 1):
    print(f"  {i:2d}. {col}")

print("\nğŸ“Š Primeras 5 filas:")
print(df_full.head())

print("\nğŸ“ˆ EstadÃ­sticas descriptivas (variables climÃ¡ticas):")
print(df_full[['temp_celsius', 'atemp_celsius', 'humidity_pct', 'windspeed_kmh', 'cnt']].describe())

print("\nğŸŒ¤ï¸ DistribuciÃ³n por clima:")
print(df_full['weather_desc'].value_counts())

print("\nğŸ—“ï¸ DistribuciÃ³n por dÃ­a de la semana:")
print(df_full.groupby('day_name')['cnt'].mean().sort_values(ascending=False))

print("\nâ° Top 5 horas con mÃ¡s rentas:")
print(df_full.groupby('hr')['cnt'].sum().sort_values(ascending=False).head())

# ============================================================================
# 2. AGREGACIÃ“N DIARIA
# ============================================================================

print("\n" + "="*80)
print("2. AGREGACIÃ“N DIARIA")
print("="*80)

df_daily = pd.read_parquet('data/processed/daily_summary.parquet')

print(f"\nDimensiones: {df_daily.shape[0]:,} dÃ­as Ã— {df_daily.shape[1]} columnas")

print("\nğŸ“‹ Columnas:")
for i, col in enumerate(df_daily.columns, 1):
    print(f"  {i:2d}. {col}")

print("\nğŸ“Š Primeras 10 filas:")
print(df_daily.head(10))

print("\nğŸ“ˆ EstadÃ­sticas de rentas diarias:")
print(df_daily['total_rentals'].describe())

print(f"\nğŸ† DÃ­a con mÃ¡s rentas: {df_daily.loc[df_daily['total_rentals'].idxmax(), 'date'].date()}")
print(f"   Total: {df_daily['total_rentals'].max():,} rentas")

print(f"\nğŸ“‰ DÃ­a con menos rentas: {df_daily.loc[df_daily['total_rentals'].idxmin(), 'date'].date()}")
print(f"   Total: {df_daily['total_rentals'].min():,} rentas")

# ============================================================================
# 3. AGREGACIÃ“N SEMANAL
# ============================================================================

print("\n" + "="*80)
print("3. AGREGACIÃ“N SEMANAL")
print("="*80)

df_weekly = pd.read_parquet('data/processed/weekly_summary.parquet')

print(f"\nDimensiones: {df_weekly.shape[0]:,} semanas Ã— {df_weekly.shape[1]} columnas")

print("\nğŸ“‹ Columnas:")
for i, col in enumerate(df_weekly.columns, 1):
    print(f"  {i:2d}. {col}")

print("\nğŸ“Š Primeras 10 semanas:")
print(df_weekly.head(10))

print("\nğŸ“ˆ EstadÃ­sticas de rentas semanales:")
print(df_weekly['total_rentals'].describe())

print(f"\nğŸ† Semana con mÃ¡s rentas:")
best_week = df_weekly.loc[df_weekly['total_rentals'].idxmax()]
print(f"   AÃ±o {best_week['year']}, Semana {best_week['week']}")
print(f"   {best_week['week_start'].date()} a {best_week['week_end'].date()}")
print(f"   Total: {best_week['total_rentals']:,} rentas")

# ============================================================================
# 4. INSIGHTS CLAVE
# ============================================================================

print("\n" + "="*80)
print("4. ğŸ” INSIGHTS CLAVE DEL ANÃLISIS")
print("="*80)

# ComparaciÃ³n usuarios casuales vs registrados
casual_pct = (df_full['casual'].sum() / df_full['cnt'].sum()) * 100
registered_pct = (df_full['registered'].sum() / df_full['cnt'].sum()) * 100

print(f"\nğŸ‘¥ DistribuciÃ³n de usuarios:")
print(f"   Casuales: {casual_pct:.1f}% ({df_full['casual'].sum():,} rentas)")
print(f"   Registrados: {registered_pct:.1f}% ({df_full['registered'].sum():,} rentas)")

# Rentas en hora pico vs no pico
peak_rentals = df_full[df_full['is_peak_hour'] == True]['cnt'].sum()
non_peak_rentals = df_full[df_full['is_peak_hour'] == False]['cnt'].sum()
peak_pct = (peak_rentals / df_full['cnt'].sum()) * 100

print(f"\nâ° Horas pico (7-9am, 5-7pm):")
print(f"   {peak_pct:.1f}% de las rentas ({peak_rentals:,})")

# Fin de semana vs dÃ­as laborales
weekend_avg = df_full[df_full['is_weekend'] == True].groupby('dteday')['cnt'].sum().mean()
weekday_avg = df_full[df_full['is_weekend'] == False].groupby('dteday')['cnt'].sum().mean()

print(f"\nğŸ“… Promedio de rentas diarias:")
print(f"   Fin de semana: {weekend_avg:.0f} rentas/dÃ­a")
print(f"   DÃ­as laborales: {weekday_avg:.0f} rentas/dÃ­a")
print(f"   Diferencia: {((weekday_avg/weekend_avg - 1) * 100):+.1f}%")

# Por estaciÃ³n
print(f"\nğŸŒ¸ Rentas por estaciÃ³n del aÃ±o:")
seasonal = df_full.groupby('season_name')['cnt'].sum().sort_values(ascending=False)
for season, total in seasonal.items():
    print(f"   {season:10s}: {total:>8,} rentas ({(total/df_full['cnt'].sum()*100):>5.1f}%)")

print("\n" + "="*80)
print("âœ… EXPLORACIÃ“N COMPLETADA")
print("="*80)

print("""
ğŸ’¡ PrÃ³ximos pasos sugeridos:

1. Crear visualizaciones:
   - GrÃ¡fico de lÃ­nea: Rentas por dÃ­a/semana
   - Heatmap: Rentas por hora del dÃ­a y dÃ­a de la semana
   - Box plot: DistribuciÃ³n de rentas por clima

2. AnÃ¡lisis adicionales:
   - CorrelaciÃ³n entre variables climÃ¡ticas y rentas
   - Impacto de festivos en demanda
   - Tendencias de crecimiento aÃ±o a aÃ±o

3. Dashboard interactivo:
   - Streamlit, Dash, o Jupyter notebook
   - Filtros por fecha, clima, estaciÃ³n
   - MÃ©tricas KPI en tiempo real

Archivos disponibles:
  ğŸ“ data/processed/bike_sharing_full.parquet
  ğŸ“ data/processed/daily_summary.parquet
  ğŸ“ data/processed/weekly_summary.parquet
""")
